{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario I: Selecting Best Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data with multiple features\n",
    "train_num = 100\n",
    "n_features = 50\n",
    "\n",
    "n_samples = 10000\n",
    "X = np.random.rand(n_samples, n_features) * 10\n",
    "true_coefs = np.ones(n_features)\n",
    "y = X @ true_coefs + 2 + np.random.randn(n_samples) * 2\n",
    "\n",
    "# Introduce some non-linearity to misspecify the model\n",
    "y = y + 1 * np.sin(X).sum(axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_num, random_state=42)\n",
    "\n",
    "# Define a range of regularization parameters\n",
    "alpha_values = np.linspace(0, 200, 100)\n",
    "\n",
    "\n",
    "best_alpha_naive, cost_naive = 0, 0\n",
    "best_alpha_cv5, cost_cv5 = 0, 0\n",
    "best_alpha_loo, cost_loo = 0, 0\n",
    "best_alpha_oracle = 0\n",
    "loop_num = 100\n",
    "\n",
    "for i in range(loop_num):\n",
    "    # Naive training loss\n",
    "    def naive_training_loss(X_train, y_train, alpha_values):\n",
    "        losses = []\n",
    "        for alpha in alpha_values:\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_train)\n",
    "            loss = mean_squared_error(y_train, y_pred)\n",
    "            losses.append(loss)\n",
    "        return losses\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    def cross_validation_5fold(X_train, y_train, alpha_values):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        avg_losses = []\n",
    "        for alpha in alpha_values:\n",
    "            fold_losses = []\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                model = Ridge(alpha=alpha)\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                y_pred = model.predict(X_val_fold)\n",
    "                loss = mean_squared_error(y_val_fold, y_pred)\n",
    "                fold_losses.append(loss)\n",
    "            avg_losses.append(np.mean(fold_losses))\n",
    "        return avg_losses\n",
    "\n",
    "    # Leave-one-out cross-validation\n",
    "    def loo_cross_validation(X_train, y_train, alpha_values):\n",
    "        loo = LeaveOneOut()\n",
    "        avg_losses = []\n",
    "        for alpha in alpha_values:\n",
    "            fold_losses = []\n",
    "            for train_index, val_index in loo.split(X_train):\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                model = Ridge(alpha=alpha)\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                y_pred = model.predict(X_val_fold)\n",
    "                loss = mean_squared_error(y_val_fold, y_pred)\n",
    "                fold_losses.append(loss)\n",
    "            avg_losses.append(np.mean(fold_losses))\n",
    "        return avg_losses\n",
    "\n",
    "    # Oracle test error\n",
    "    def oracle_test_error(X_train, y_train, X_test, y_test, alpha_values):\n",
    "        test_errors = []\n",
    "        for alpha in alpha_values:\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_error = mean_squared_error(y_test, y_pred)\n",
    "            test_errors.append(test_error)\n",
    "        return test_errors\n",
    "\n",
    "    # Calculate losses for each method\n",
    "    naive_losses = naive_training_loss(X_train, y_train, alpha_values)\n",
    "    cv5_losses = cross_validation_5fold(X_train, y_train, alpha_values)\n",
    "    loo_losses = loo_cross_validation(X_train, y_train, alpha_values)\n",
    "    oracle_errors = oracle_test_error(X_train, y_train, X_test, y_test, alpha_values)\n",
    "\n",
    "# Find the best alpha for each method\n",
    "    best_alpha_naive += alpha_values[np.argmin(naive_losses)] / loop_num\n",
    "    best_alpha_cv5 += alpha_values[np.argmin(cv5_losses)] / loop_num\n",
    "    best_alpha_loo += alpha_values[np.argmin(loo_losses)] / loop_num\n",
    "    best_alpha_oracle += alpha_values[np.argmin(oracle_errors)] / loop_num\n",
    "\n",
    "    cost_naive += oracle_errors[np.argmin(naive_losses)] / loop_num \n",
    "    cost_cv5 += oracle_errors[np.argmin(cv5_losses)] / loop_num\n",
    "    cost_loo += oracle_errors[np.argmin(loo_losses)] / loop_num\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Best alpha and cost (Naive Training Loss): {best_alpha_naive}, {cost_naive}\")\n",
    "print(f\"Best alpha and cost (5-Fold Cross-Validation): {best_alpha_cv5}, {cost_naive}\")\n",
    "print(f\"Best alpha and cost (Leave-One-Out Cross-Validation): {best_alpha_loo}, {cost_naive}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario II: Selecting Different Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "plugin 0.71 39.94704327392565\n",
      "cv 0.96 37.25798923636545\n",
      "loo 0.95 37.259071531396415\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "loop_num = 100\n",
    "# Generate synthetic data with multiple features\n",
    "train_num = 400\n",
    "n_samples = 10000\n",
    "n_features = 10\n",
    "\n",
    "naive_prob, naive_cost = 0, 0\n",
    "cv_prob, cv_cost = 0, 0\n",
    "loo_prob, loo_cost = 0, 0\n",
    "\n",
    "for i in range(loop_num):\n",
    "    print(i)\n",
    "    X = np.random.rand(n_samples, n_features) * 10\n",
    "    true_coefs = np.ones(n_features)\n",
    "    y = X @ true_coefs + 2 + np.random.randn(n_samples) * 2\n",
    "\n",
    "    # Introduce some non-linearity to misspecify the model\n",
    "    alpha = random.uniform(0, 5)\n",
    "    y = y + alpha * np.sin(X).sum(axis=1)\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_num, random_state=42)\n",
    "\n",
    "    # Define the models with fixed configurations\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0),  # Default alpha for Ridge\n",
    "        \"kNN\": KNeighborsRegressor(n_neighbors = 5),  # Default n_neighbors for kNN\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators = 50, max_samples = 0.5, random_state = 42)  # Default n_estimators for Random Forest\n",
    "    }\n",
    "\n",
    "    # Evaluate models using different criteria\n",
    "    def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "        results = {}\n",
    "        for model_name, model in models.items():\n",
    "            # Naive training loss\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            naive_loss = mean_squared_error(y_train, y_pred_train)\n",
    "            \n",
    "            # 5-fold cross-validation\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            cv5_losses = []\n",
    "            for train_index, val_index in kf.split(X_train):\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                y_pred_val = model.predict(X_val_fold)\n",
    "                loss = mean_squared_error(y_val_fold, y_pred_val)\n",
    "                cv5_losses.append(loss)\n",
    "            avg_cv5_loss = np.mean(cv5_losses)\n",
    "            \n",
    "            # Leave-one-out cross-validation\n",
    "            loo = LeaveOneOut()\n",
    "            loo_losses = []\n",
    "            for train_index, val_index in loo.split(X_train):\n",
    "                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "                model.fit(X_train_fold, y_train_fold)\n",
    "                y_pred_val = model.predict(X_val_fold)\n",
    "                loss = mean_squared_error(y_val_fold, y_pred_val)\n",
    "                loo_losses.append(loss)\n",
    "            avg_loo_loss = np.mean(loo_losses)\n",
    "            \n",
    "            # Oracle test error\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            oracle_error = mean_squared_error(y_test, y_pred_test)\n",
    "            \n",
    "            # Store results\n",
    "            results[model_name] = {\n",
    "                \"Naive Loss\": naive_loss,\n",
    "                \"CV5 Loss\": avg_cv5_loss,\n",
    "                \"LOO Loss\": avg_loo_loss,\n",
    "                \"Oracle Error\": oracle_error\n",
    "            }\n",
    "            \n",
    "        return results\n",
    "\n",
    "    # Evaluate all models\n",
    "    results = evaluate_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Display results\n",
    "    # for model_name, metrics in results.items():\n",
    "    #     print(f\"Model: {model_name}\")\n",
    "    #     for metric_name, value in metrics.items():\n",
    "    #         print(f\"  {metric_name}: {value:.4f}\")\n",
    "\n",
    "    # find avg cost and matches probability for each method\n",
    "\n",
    "    ranked_items = sorted(results.items(), key=lambda item: item[1][\"Oracle Error\"])\n",
    "    # Best performance index is ranked_keys[0]\n",
    "    ranked_keys = [item[0] for item in ranked_items]\n",
    "\n",
    "    rank_naive = sorted(results.items(), key=lambda item: item[1][\"Naive Loss\"])\n",
    "    # Best performance\n",
    "    ranked_naive_keys = [item[0] for item in rank_naive]\n",
    "    if ranked_naive_keys[0] == ranked_keys[0]:\n",
    "        naive_prob += 1\n",
    "    naive_cost += results[ranked_naive_keys[0]]['Oracle Error'] / loop_num\n",
    "\n",
    "    rank_cv = sorted(results.items(), key=lambda item: item[1][\"CV5 Loss\"])\n",
    "    # Best performance\n",
    "    ranked_cv_keys = [item[0] for item in rank_cv]\n",
    "    if ranked_cv_keys[0] == ranked_keys[0]:\n",
    "        cv_prob += 1\n",
    "    cv_cost += results[ranked_cv_keys[0]]['Oracle Error'] / loop_num\n",
    "\n",
    "    rank_loo = sorted(results.items(), key=lambda item: item[1][\"LOO Loss\"])\n",
    "    # Best performance\n",
    "    ranked_loo_keys = [item[0] for item in rank_loo]\n",
    "    if ranked_loo_keys[0] == ranked_keys[0]:\n",
    "        loo_prob += 1\n",
    "    loo_cost += results[ranked_loo_keys[0]]['Oracle Error'] / loop_num\n",
    "    \n",
    "print('plugin', naive_prob / loop_num, naive_cost)\n",
    "print('cv', cv_prob / loop_num, cv_cost)\n",
    "print('loo', loo_prob  / loop_num, loo_cost)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
